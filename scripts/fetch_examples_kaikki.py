import json
import re
import requests

VOCAB_FILE = 'app/data/vocabulary.ts'
KAIKKI_URL = 'https://kaikki.org/dictionary/English/kaikki.org-dictionary-English.jsonl'

def get_words_needing_examples():
    with open(VOCAB_FILE, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # Find words that have the placeholder example
    # Pattern: word: "Word", ... example: "Example for Word"
    # We need to be careful with regex.
    
    # Let's just find all words and their current example
    # We will store them in a dictionary: word -> {start_index, end_index, current_example}
    
    words_to_update = {}
    
    # Regex to find the object structure
    # We assume the structure is consistent as generated by the previous script
    # Handle both single and double quotes
    pattern = re.compile(r"word:\s*['\"]([^'\"]+)['\"],\s*translation:\s*['\"]([^'\"]+)['\"],\s*example:\s*['\"]([^'\"]+)['\"]")
    
    for match in pattern.finditer(content):
        word = match.group(1)
        example = match.group(3)
        
        if example == f"Example for {word}":
            words_to_update[word] = True
            
    return words_to_update

def stream_and_find_examples(words_to_update):
    print(f"Looking for examples for {len(words_to_update)} words...")
    found_examples = {}
    
    # Create a case-insensitive map
    # word_lower -> original_word
    words_map = {w.lower(): w for w in words_to_update}
    
    with requests.get(KAIKKI_URL, stream=True) as r:
        r.raise_for_status()
        for line in r.iter_lines():
            if not line:
                continue
            
            try:
                entry = json.loads(line)
            except json.JSONDecodeError:
                continue
                
            word = entry.get('word')
            if not word:
                continue
                
            word_lower = word.lower()
            
            if word_lower in words_map:
                original_word = words_map[word_lower]
                
                if original_word in found_examples:
                    continue

                senses = entry.get('senses', [])
                for sense in senses:
                    examples = sense.get('examples', [])
                    if examples:
                        # Get the first example text
                        ex_text = examples[0].get('text')
                        if ex_text:
                            found_examples[original_word] = ex_text
                            break
                
                if len(found_examples) % 100 == 0:
                    print(f"Found {len(found_examples)} examples so far...")
                    
            if len(found_examples) >= len(words_to_update):
                break
    
    return found_examples

def update_vocab_file(found_examples):
    with open(VOCAB_FILE, 'r', encoding='utf-8') as f:
        content = f.read()
        
    new_content = content
    
    count = 0
    for word, example in found_examples.items():
        # Escape single quotes in example because we will use single quotes for the string
        safe_example = example.replace("'", "\\'")
        
        # Replace the specific placeholder for this word
        # We look for: example: 'Example for Word'
        
        placeholder = f"example: 'Example for {word}'"
        replacement = f"example: '{safe_example}'"
        
        if placeholder in new_content:
            new_content = new_content.replace(placeholder, replacement)
            count += 1
        else:
            # Try double quotes just in case
            placeholder_dq = f'example: "Example for {word}"'
            replacement_dq = f'example: "{example.replace('"', '\\"')}"'
            if placeholder_dq in new_content:
                new_content = new_content.replace(placeholder_dq, replacement_dq)
                count += 1
            
    with open(VOCAB_FILE, 'w', encoding='utf-8') as f:
        f.write(new_content)
        
    print(f"Updated {count} words with new examples.")

def main():
    words = get_words_needing_examples()
    if not words:
        print("No words need examples.")
        return

    print(f"Found {len(words)} words needing examples.")
    
    examples = stream_and_find_examples(words)
    print(f"Found total {len(examples)} examples.")
    
    update_vocab_file(examples)

if __name__ == "__main__":
    main()
